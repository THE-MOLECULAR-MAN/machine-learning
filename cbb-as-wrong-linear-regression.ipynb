{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! /usr/local/anaconda3/bin/python3 -m pip install missingno scikit-learn matplotlib seaborn numpy pandas tensorflow==2.12 blosc2==2.0.0 cython==0.29.21 FuzzyTM==1.0\n",
    "# /usr/local/anaconda3/bin/python3 -m pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format\n",
    "# tf.keras.backend.set_floatx('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('Comedy_bang_bang_podcast_dataset - full_dataset-v15.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some unused features, data filtering\n",
    "# this only works if the columns exist\n",
    "train_df.drop(['year_elligible_for_best_of','episode_title','synopsis_and_segments','fandom_wikia_suffix','weight_flat','weight_inverse','weight_linear','best_of_rank'], axis=1, inplace=True)\n",
    "\n",
    "train_df['date_episode_published'] = pd.to_datetime(train_df['date_episode_published'])\n",
    "# convert it again to avoid later issues:\n",
    "# https://stackoverflow.com/questions/69282305/how-do-i-solve-this-error-typeerror-float-argument-must-be-a-string-or-a-num\n",
    "train_df['date_episode_published'] = train_df['date_episode_published'].apply(pd.Timestamp.timestamp)\n",
    "\n",
    "# see if there are any null values in the data set\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df.drop(train_df.loc[train_df['data_set']=='ignored'].index, inplace=True)\n",
    "train_df.drop(train_df.loc[train_df['data_set']=='prediction'].index, inplace=True)\n",
    "\n",
    "# don't need this column anymore\n",
    "train_df.drop(['data_set'], axis=1, inplace=True)\n",
    "\n",
    "# students.grade = students.grade.astype('int64')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode the episode_type\n",
    "train_df = pd.get_dummies(train_df, columns=['episode_type', ])\n",
    "\n",
    "#   episode_type\n",
    "# TODO: run my other python function to manipulate the guests_and_characters_from_wikipedia_semicolon_delimited column\n",
    "train_df.drop(['guests_and_characters_from_wikipedia_semicolon_delimited'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "new_column_order = ['episode_number', 'date_episode_published', 'duration_in_minutes', 'episode_type_anniversary', \n",
    "                    'episode_type_guest_host', 'episode_type_hoilday', 'episode_type_holiday', 'episode_type_live', \n",
    "                    'episode_type_regular', 'episode_type_special', 'episode_type_takeover', \n",
    "                    'is_on_best_of_boolean']\n",
    "# train_df = train_df[new_column_order]\n",
    "train_df = train_df.reindex(columns=new_column_order)\n",
    "\n",
    "train_df.head()\n",
    "\n",
    "# reorder columns so that the \n",
    "# df = pd.DataFrame(technologies)\n",
    "# temp_cols=df.columns.tolist()\n",
    "# index=df.columns.get_loc(\"Duration\")\n",
    "# new_cols=temp_cols[index:index+1] + temp_cols[0:index] + temp_cols[index+1:]\n",
    "# df=df[new_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUMBER_OF_SPLITS = 5\n",
    "# for i, new_df in enumerate(np.array_split(train_df,NUMBER_OF_SPLITS)):\n",
    "#     with open(f\"out{i}.csv\",\"w\") as fo:\n",
    "#             fo.write(new_df.to_csv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing data detection\n",
    "msno.matrix(train_df, figsize = (10,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that all the bars in the above picture have the same height and thus, we conclude that we don't have any missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets see the Distribution of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 2, ncols =1)\n",
    "fig.set_size_inches(20,30)\n",
    "sns.boxplot(data=train_df,orient=\"v\",ax=axes[0]) # To see if we need to scale our data\n",
    "sns.boxplot(data=train_df, y = \"is_on_best_of_boolean\", orient = \"pH\", ax=axes[1]) # to see the distribution of quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first figure, we see that there are a lot of outliers as dots in the figure. It seems that there\n",
    "is a need to scale the data as we cannot see other feature values. \n",
    "\n",
    "In the second figure, we see that there are 3 outliers and the distribution of wine quality. Most of the feature values belong to the wine \n",
    "quality between 5 and 6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us now see the correlation of features and then we need to remove the highly correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = train_df.corr()\n",
    "mask = np.array(corr_mat)\n",
    "mask[np.tril_indices_from(mask)] = False\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(20,10)\n",
    "sns.heatmap(corr_mat, mask = mask, vmax = 0.8, square = True, annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The density and residual sugar have high dependency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into train and test and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_column_name='is_on_best_of_boolean'\n",
    "X = train_df.iloc[:, :-1]\n",
    "y = train_df.iloc[: , -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding an extra column for the constant used in calculation of Linear Regression\n",
    "X = np.append(arr = np.ones((X.shape[0],1)), values = X, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# standardscaler fit_transform TypeError float argument must be a string or a real number not \"Timestamp\"\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use of pipeline for model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the results with visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred, c ='g')\n",
    "plt.xlabel('True Quality')\n",
    "plt.ylabel('Predicted Quality')\n",
    "plt.title('Predicted quality vs True quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
