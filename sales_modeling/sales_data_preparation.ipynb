{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sales Modeling - Data Preparation\n",
    "This script takes a raw CSV file generated by Salesforce and converts it into a CSV file that is ready to use for training machine learning models.\n",
    "\n",
    "3/4/24 - This script is not finished."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some exclusions for PEP8 that don't apply when the Jupyter Notebook\n",
    "#   is exported to .py file\n",
    "# pylint: disable=pointless-statement\n",
    "# pylint: disable=fixme\n",
    "# pylint: disable=expression-not-assigned\n",
    "# pylint: disable=missing-module-docstring\n",
    "# pylint: disable=invalid-name\n",
    "\n",
    "import os\n",
    "import json\n",
    "# import sys\n",
    "# import re\n",
    "from math import isnan\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "# from pandas._libs.tslibs.parsing import DateParseError\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data into a Pandas dataframe\n",
    "Define the path to the dataset file\n",
    "Define the name of the label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = os.getcwd()\n",
    "infile = os.path.join(rootdir, 'data', 'sales_data.csv')\n",
    "df = pd.read_csv(infile)\n",
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customized variables for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can be either \"train\" or \"predict\"\n",
    "DATA_PREP_MODE = 'train'\n",
    "\n",
    "LABEL_COLUMN_NAME = \"Won\"\n",
    "# NORMALIZE_METHOD = \"min_max\"\n",
    "\n",
    "FEATURE_VALID_RANGES = {\n",
    "    'Age': {'min': 20, 'max': 720},\n",
    "    'Annual Recurring Revenue (ARR)': {'min': 2000, 'max': 2000000},\n",
    "    'quarter_closed': {'min': 1, 'max': 4},\n",
    "    'quarter_created': {'min': 1, 'max': 4},\n",
    "}\n",
    "\n",
    "FEATURE_PROPER_DATATYPES = {\"Annual Recurring Revenue (ARR)\": \"int64\",\n",
    "               \"Age\": \"int64\",\n",
    "               'partner_involved': \"bool\"\n",
    "               }\n",
    "\n",
    "FEATURES_TO_OHE = ['Team Territory Group', 'Opportunity Owner',\n",
    "                         'Industry', 'primary_product']\n",
    "\n",
    "# def get_stat(col_name, stat_name):\n",
    "#     \"\"\"docstring TBD\"\"\"\n",
    "    # return df.describe(include=\"all\").loc[stat_name].loc[col_name]\n",
    "\n",
    "# Finding the percentiles:\n",
    "# def find_nearest_index(array, value):\n",
    "#     \"\"\"docstring TBD\"\"\"\n",
    "#     array = np.asarray(array)\n",
    "#     idx = (np.abs(array - value)).argmin()\n",
    "#     return idx\n",
    "\n",
    "# validate configuration above.\n",
    "assert DATA_PREP_MODE in ['train', 'predict'], \\\n",
    "    \"DATA_PREP_MODE must be either train or predict. Exiting\"\n",
    "    \n",
    "if DATA_PREP_MODE == 'train':\n",
    "    FEATURE_PROPER_DATATYPES[LABEL_COLUMN_NAME] = 'bool'\n",
    "    # print(FEATURE_PROPER_DATATYPES)\n",
    "\n",
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting/converting the feature data types\n",
    "\n",
    "#### Extracting the Salesforce JSON fields into individual fields\n",
    "Salesforce has a strict limitation on the number of columns it can export in a report. One way around this is to combine several fields into a single one using JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establishing invalid default values to create the features\n",
    "df['quarter_created'] = 0\n",
    "df['quarter_closed'] = 0\n",
    "df['primary_product'] = None\n",
    "df['partner_involved'] = None\n",
    "\n",
    "# convert JSON to new columns\n",
    "for index_iter in df.index:\n",
    "    fields_as_json_str = df['array_of_sfdc_formulas'][index_iter]\n",
    "    fields_as_dict = json.loads(fields_as_json_str)\n",
    "    for colname, value in fields_as_dict.items():\n",
    "        df.loc[df.index == index_iter, colname] = value\n",
    "\n",
    "\n",
    "for colname, newdatatype in FEATURE_PROPER_DATATYPES.items():\n",
    "    if DATA_PREP_MODE == \"train\" or (DATA_PREP_MODE == \"predict\" and colname != LABEL_COLUMN_NAME):\n",
    "        df[colname] = df[colname].astype(newdatatype)\n",
    "\n",
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop the unused features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\n",
    "    columns=[\n",
    "        \"Annual Recurring Revenue (ARR) Currency\",\n",
    "        \"Opportunity ID\",     # leave this is for easy re-joining the data\n",
    "        \"array_of_sfdc_formulas\"\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting salesforce user error and other non-use cases\n",
    "\n",
    "Removes the following:\n",
    "* opps with $0 or less ARR - these are refunds, free upgrades, etc.\n",
    "* opps with an age of less than 14 days - these were likely duplicates or multiple opps made for quoting purposes\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colname, ranges_dict in FEATURE_VALID_RANGES.items():\n",
    "    min_value = ranges_dict['min']\n",
    "    max_value = ranges_dict['max']\n",
    "    indexes_to_drop = df[ (df[colname] < min_value) | (df[colname] > max_value) ].index\n",
    "    df.drop(indexes_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winsorizing numerical outliers\n",
    "Description TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Winsorize the top 1% and bottom 1%\n",
    "# percentile = 0.01\n",
    "\n",
    "# for iter_column_name in df.select_dtypes(include=np.number).columns.tolist():\n",
    "#     new_column_name = iter_column_name + \"_winsorized\"\n",
    "\n",
    "#     winsorized_data = stats.mstats.winsorize(\n",
    "#         df[iter_column_name], limits=[percentile, percentile], inplace=False\n",
    "#     )\n",
    "\n",
    "#     if (winsorized_data == df[iter_column_name]).all():\n",
    "#         print(\n",
    "#             f\"Winsorization on column {iter_column_name} had no effect. Not changing this column.\"\n",
    "#         )\n",
    "#         continue\n",
    "\n",
    "#     df[new_column_name] = winsorized_data\n",
    "#     df.drop(columns=iter_column_name, inplace=True)\n",
    "#     print(\n",
    "#         f\"Winsorized column {iter_column_name} to {new_column_name} and removed original column.\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing missing numerical values w/ their mean\n",
    "Description TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing numerical ranges\n",
    "Description TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize(df_local, column_name, normalize_method_name):\n",
    "#     \"\"\"docstring TBD\"\"\"\n",
    "#     df_temp = df_local.copy()\n",
    "#     new_columnname = column_name + \"_normalized\"\n",
    "\n",
    "#     if normalize_method_name == \"absolute_range\":\n",
    "#         df_temp[new_columnname] = (\n",
    "#             df_temp[column_name] / df_temp[column_name].abs().max()\n",
    "#         )\n",
    "\n",
    "#     elif normalize_method_name == \"min_max\":\n",
    "#         # rescales a features to be in the range [0,1]\n",
    "#         df_temp[new_columnname] = (\n",
    "#             df_temp[column_name] - df_temp[column_name].min()\n",
    "#         ) / (df_temp[column_name].max() - df_temp[column_name].min())\n",
    "\n",
    "#     elif normalize_method_name == \"z_score\":\n",
    "#         df_temp[new_columnname] = (\n",
    "#             df_temp[column_name] - df_temp[column_name].mean()\n",
    "#         ) / df_temp[column_name].std()\n",
    "\n",
    "#     else:\n",
    "#         raise NameError(\"Unrecogized normalization method\")\n",
    "\n",
    "#     df_temp.drop(columns=column_name, inplace=True)\n",
    "#     print(\n",
    "#         f\"Normalized column {column_name} into {new_columnname} using {normalize_method_name}. Removed original.\"\n",
    "#     )\n",
    "#     return df_temp\n",
    "\n",
    "\n",
    "# # iterate through the list of current numeric columns\n",
    "# for iter_column_name in df.select_dtypes(include=np.number).columns.tolist():\n",
    "#     df = normalize(df, iter_column_name, NORMALIZE_METHOD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encoding strings\n",
    "sales rep names, industries, products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter_column_name in FEATURES_TO_OHE:\n",
    "    # define a new column names, it automatically adds a _ to the end of the prefix\n",
    "    new_column_prefix = iter_column_name\n",
    "\n",
    "    # create a one-hot encoded version in a new dataframe\n",
    "    temp_df = pd.get_dummies(df[iter_column_name], prefix=new_column_prefix)\n",
    "\n",
    "    # merge the new dataframe into the existing one\n",
    "    df = df.join(temp_df)\n",
    "\n",
    "    # remove the original column now that it has been encoded \n",
    "    # into the existing dataframe\n",
    "    df.drop(columns=iter_column_name, inplace=True)\n",
    "    \n",
    "    print(f'One-hot encoded: {iter_column_name} into {new_column_prefix}*')\n",
    "    \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-order the columns\n",
    "Sort the column names alphabetically, but make sure the 'label' column is always last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphabetically sort the column names, but leave the label as the last column\n",
    "# since the label will be dropped for predictive datasets\n",
    "column_order = sorted(df.columns)\n",
    "\n",
    "if DATA_PREP_MODE == \"train\":\n",
    "    column_order.remove(LABEL_COLUMN_NAME)\n",
    "    column_order.append(LABEL_COLUMN_NAME)\n",
    "\n",
    "df = df.reindex(column_order, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "# check for any remaining strings\n",
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the final datatypes before exporting to CSV\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: check the % of labels that are True vs False, ensure balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic data validation before modeling\n",
    "\n",
    "Check ranges, values, datatypes, missing values, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colname, ranges_dict in FEATURE_VALID_RANGES.items():\n",
    "    min_value = ranges_dict['min']\n",
    "    max_value = ranges_dict['max']\n",
    "    for index, row in df.iterrows():\n",
    "        val = df[colname][index]\n",
    "        assert min_value <= val <= max_value, f'Out of range: {colname} value of {val} is not between {min_value} and {max_value}'\n",
    "        \n",
    "print(\"all data tests passed successfully.\")\n",
    "\n",
    "# df.head(3)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store prepped data in new CSV\n",
    "Makes it easy to run in separate notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = os.path.splitext(infile)[0] + \"_\" + DATA_PREP_MODE + \".csv\"\n",
    "df.to_csv(outfile, index=False)\n",
    "print(f\"{DATA_PREP_MODE} data saved to new CSV file:\\n{outfile}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
