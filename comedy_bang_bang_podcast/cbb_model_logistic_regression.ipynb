{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comedy Bang Bang Podcast Best Of - Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some exclusions for PEP8 that don't apply when the Jupyter Notebook\n",
    "#   is exported to .py file\n",
    "# pylint: disable=pointless-statement\n",
    "# pylint: disable=fixme\n",
    "# pylint: disable=expression-not-assigned\n",
    "# pylint: disable=missing-module-docstring\n",
    "# pylint: disable=invalid-name\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting custom parameters for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of training data to use for test\n",
    "TEST_SIZE = 0.33\n",
    "\n",
    "# random seed\n",
    "RANDOM_STATE = 42069\n",
    "\n",
    "# the name for the column that indicates the label/target\n",
    "# the training CSV file should have headers\n",
    "LABEL_COLUMN_NAME = \"label\"\n",
    "\n",
    "# acceptable values: accuracy, f1, precision, recall\n",
    "# METRIC_TO_MEASURE = \"accuracy\"\n",
    "\n",
    "NUM_EPISODES_IN_2024_BEST_OF = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import and validation\n",
    "\n",
    "These code blocks load the prepared data from a CSV file, and then run a variety of tests to validate the values are within expected ranges. This ensures the data will produce useful models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = os.path.join(\n",
    "    os.getcwd(), \"data\", \"Comedy_bang_bang_podcast_dataset_2023-final_train.csv\"\n",
    ")\n",
    "\n",
    "# index_col is required, since that is how it is output from the data prep script\n",
    "df = pd.read_csv(train_filename, index_col=0, header=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the features and their datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data type validation\n",
    "Verify that only numeric and boolean features are present. All strings should have been One Hot Encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that there are only numeric and boolean datatypes left\n",
    "# there should not be any strings left\n",
    "for index, value in df.dtypes.items():\n",
    "    assert value in [\n",
    "        \"float64\",\n",
    "        \"bool\",\n",
    "        \"int64\",\n",
    "    ], f\"Column name {index} is not numeric or boolean- found {value}. All features at this point should be numeric or boolean. Exiting.\"\n",
    "\n",
    "print(\"Feature datatype check passed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the episode number and year ranges. The first year of Comedy Bang Bang did not feature a Best Of list, so episodes 1-33 should be removed. The model should not be training on episodes elligible for 2023.\n",
    "\n",
    "This block should output:\n",
    "\n",
    "```Episode range of df: [35, 785]```\n",
    "\n",
    "```Year elligible range of df: [2010, 2022]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_episode_num_min = min(df.index)\n",
    "df_episode_num_max = max(df.index)\n",
    "print(f\"Episode range of df: [{df_episode_num_min}, {df_episode_num_max}]\")\n",
    "\n",
    "df_year_elligible_min = min(df['year_elligible_for_best_of'])\n",
    "df_year_elligible_max = max(df['year_elligible_for_best_of'])\n",
    "\n",
    "print(f\"Year elligible range of df: [{df_year_elligible_min}, {df_year_elligible_max}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "### Split up the features and label for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[LABEL_COLUMN_NAME]\n",
    "X = df.drop(columns=LABEL_COLUMN_NAME, axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"Number of examples: \" + str(X.shape[0]))\n",
    "print(\"\\nNumber of Features:\" + str(X.shape[1]))\n",
    "print(str(list(X.columns)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that builds, runs, and evaluates a model given hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_LR(X_train, y_train, X_test, y_test, c=1):\n",
    "    '''\n",
    "    Fit a Linear Regression classifier to the training data X_train, y_train.\n",
    "    Return the loss and accuracy of resulting predictions on the test set.\n",
    "    Parameters:\n",
    "        C = Factor that controls how much regularization is applied to the model.\n",
    "    '''\n",
    "    model = LogisticRegression(C=c)    \n",
    "    model.fit(X_train, y_train)\n",
    "    probability_predictions = model.predict_proba(X_test)\n",
    "    l_loss = log_loss(y_test, probability_predictions)\n",
    "    class_label_predictions = model.predict(X_test)\n",
    "    acc_score = accuracy_score(y_test, class_label_predictions)\n",
    "    \n",
    "    return l_loss, acc_score\n",
    "\n",
    "    # metrics = {\n",
    "    #     \"accuracy\": sklm.accuracy_score(y_test1, class_label_predictions),\n",
    "    #     \"f1\": sklm.f1_score(y_test1, class_label_predictions),\n",
    "    #     \"precision\": sklm.precision_score(y_test1, class_label_predictions),\n",
    "    #     \"recall\": sklm.recall_score(y_test1, class_label_predictions),\n",
    "    #     \"logloss\": log_loss(y_test, probability_predictions)\n",
    "    # }\n",
    "\n",
    "    # return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on different hyperparameter values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define ranges of hyperparameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = [10**i for i in range(-10,10)]\n",
    "\n",
    "ll_cs = []\n",
    "acc_cs = []\n",
    "\n",
    "for iter_c in cs:\n",
    "    loss, acc = train_test_LR(X_train, y_train, X_test, y_test, c=iter_c)\n",
    "    ll_cs.append(loss)\n",
    "    acc_cs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5)) \n",
    "\n",
    "ax = sns.barplot(x=cs, y=ll_cs)\n",
    "g = ax.set_xticklabels([f'10^{i}' for i in range(-10,10)])\n",
    "ax.set_xlabel('Regularization HyperParameter: C')\n",
    "ax.set_ylabel('Log Loss')\n",
    "g = plt.title('Log Loss Test Performance by Regularization Weight C')\n",
    "\n",
    "# finding the minimum:\n",
    "log_loss_min_value = min(ll_cs)\n",
    "c_value_at_min_log_loss = cs[np.argmin(ll_cs)]\n",
    "print(f'Log loss is minimized at C = {c_value_at_min_log_loss} where log loss = {log_loss_min_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "x = np.log10(cs)\n",
    "\n",
    "sns.lineplot(x=x, y=acc_cs, marker='o')\n",
    "\n",
    "plt.title(\"Accuracy Test Performance by Regularization Weight C\")\n",
    "plt.xlabel(\"Log10 of Regularization HyperParameter: C\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "# finding the maximum accuracy:\n",
    "ind = np.argmax(acc_cs)\n",
    "max_accuracy = acc_cs[ind]\n",
    "c_value_at_max_acc = cs[ind]\n",
    "print(f'Accuracy is maximized at value {max_accuracy} , where C = {c_value_at_max_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Optimal model against the 2023 Best Of List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_filename = os.path.join(\n",
    "    os.getcwd(), \"data\", \"Comedy_bang_bang_podcast_dataset_2023-final_predict.csv\"\n",
    ")\n",
    "df_predict = pd.read_csv(predict_filename, index_col=0, header=0)\n",
    "\n",
    "df_predict.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a model against 2023 episodes data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the ground truth (label) values for the 2023 episodes\n",
    "y2024 = df_predict[LABEL_COLUMN_NAME]\n",
    "\n",
    "# extract the features for the 2023 episodes\n",
    "X2024 = df_predict.drop(columns=LABEL_COLUMN_NAME, axis=1)\n",
    "\n",
    "# create a new model based on the optimal C value\n",
    "optimal_model = LogisticRegression(C=c_value_at_max_acc)\n",
    "\n",
    "# fit it using ALL the training data, don't leave any test data\n",
    "optimal_model.fit(X, y)\n",
    "\n",
    "# predict the binary category for each 2023 episode\n",
    "class_label_predictions_2024 = optimal_model.predict(X2024)\n",
    "\n",
    "# compare the ground truth to the prediction of the binary category\n",
    "acc_score_2024 = accuracy_score(y2024, class_label_predictions_2024)\n",
    "\n",
    "# print the accuracy\n",
    "print(acc_score_2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe that will house all the results plus the ground truth\n",
    "y2024_df = df_predict[LABEL_COLUMN_NAME].to_frame()\n",
    "y2024_df['predict_logistic_regression_predict'] = class_label_predictions_2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract just the probability [0,1] that the episode is likely to be on the\n",
    "# best of.\n",
    "probability_predictions_2024 = optimal_model.predict_proba(X2024)[:,1]\n",
    "\n",
    "# create an empty dataframe that has the same index as the other\n",
    "probability_predictions_2024_df = pd.DataFrame(index=X2024.index)\n",
    "\n",
    "# assign the extracted values to this temporary dataframe\n",
    "probability_predictions_2024_df['prob'] = probability_predictions_2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the results into a single dataframe\n",
    "# have to force it to use the indexes for some reason\n",
    "y2024_df = y2024_df.merge(probability_predictions_2024_df,\n",
    "                          left_index=True, right_index=True)\n",
    "y2024_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display the final predictions for which episodes will be on the 2023 Best of List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2024_df.sort_values(by='prob', ascending=False).head(NUM_EPISODES_IN_2024_BEST_OF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
