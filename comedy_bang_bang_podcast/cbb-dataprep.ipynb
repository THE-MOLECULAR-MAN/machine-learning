{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some exclusions for PEP8 that don't apply when the Jupyter Notebook\n",
    "# is exported to .py file since it screws up some of the formatting\n",
    "# pylint: disable=pointless-statement\n",
    "# pylint: disable=fixme\n",
    "# pylint: disable=expression-not-assigned\n",
    "# pylint: disable=missing-module-docstring\n",
    "# pylint: disable=invalid-name\n",
    "# pylint: trailing-newlines\n",
    "\n",
    "import os\n",
    "# from math import isnan\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "# from pandas._libs.tslibs.parsing import DateParseError\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data into a Pandas dataframe\n",
    "Define the path to the dataset file\n",
    "Define the name of the label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = os.getcwd()\n",
    "infile = os.path.join(rootdir, 'data',\n",
    "                      'Comedy_bang_bang_podcast_dataset - full_dataset-v16.csv')\n",
    "\n",
    "df = pd.read_csv(infile)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customized variables for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LABEL_COLUMN_NAME = 'is_on_best_of_boolean'\n",
    "\n",
    "NORMALIZE_METHOD = 'min_max'\n",
    "\n",
    "NUM_TOP_ACTORS_TO_ONE_HOT_ENCODE = 100\n",
    "NUM_TOP_CHARS_TO_ONE_HOT_ENCODE = 50\n",
    "\n",
    "INTERESTING_PERCENTILES = [0.1, 0.25, 0.40, 0.50, 0.632, 0.666, 0.75, 0.8, 0.9]\n",
    "\n",
    "def get_stat(col_name, stat_name):\n",
    "    \"\"\"docstring TBD\"\"\"\n",
    "    return df.describe(include='all').loc[stat_name].loc[col_name]\n",
    "\n",
    "\n",
    "# Finding the percentiles:\n",
    "def find_nearest_index(array, value):\n",
    "    \"\"\"docstring TBD\"\"\"\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a feature that tracks if the episode is divisible by 50 or 100\n",
    "# Scott treats these episodes almost as anniversary episodes\n",
    "\n",
    "df['hundo'] = df['episode_number'].mod(50) == 0\n",
    "# df.loc[df['hundo'] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing columns that the model doesn't use\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['episode_number', 'year_elligible_for_best_of',\n",
    "                   'episode_title', 'synopsis_and_segments',\n",
    "                   'fandom_wikia_suffix', 'best_of_rank'], inplace=True)\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling the Episode published Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the date\n",
    "df['date_episode_published_datetime'] = \\\n",
    "                    pd.to_datetime(df['date_episode_published'], errors='raise')\n",
    "\n",
    "# convert date to just the month\n",
    "df['month_published_int'] = \\\n",
    "                pd.DatetimeIndex(df['date_episode_published_datetime']).month\n",
    "\n",
    "df.drop(columns = ['date_episode_published', 'date_episode_published_datetime'],\n",
    "        inplace=True)\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove episodes released before the Best Of existed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove super old episodes that aren't useful\n",
    "rows_to_drop = df[df['data_set'] == 'ignored'].index\n",
    "df.drop(rows_to_drop, inplace=True)\n",
    "\n",
    "df['data_set'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the label to a boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert label to Boolean\n",
    "df['label'] = df[LABEL_COLUMN_NAME].astype('bool')\n",
    "df.drop(columns= LABEL_COLUMN_NAME, inplace=True)\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winsorizing numerical outliers\n",
    "Description TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winsorize the top 1% and bottom 1%\n",
    "percentile = 0.01\n",
    "\n",
    "for iter_column_name in df.select_dtypes(include=np.number).columns.tolist():\n",
    "\n",
    "    new_column_name = iter_column_name + '_winsorized'\n",
    "\n",
    "    winsorized_data = stats.mstats.winsorize(df[iter_column_name],\n",
    "                           limits=[percentile, percentile],\n",
    "                           inplace=False)\n",
    "\n",
    "    if (winsorized_data == df[iter_column_name]).all():\n",
    "        print(f'Winsorization on column {iter_column_name} had no effect. Not changing this column.')\n",
    "        continue\n",
    "    else:\n",
    "        df[new_column_name] = winsorized_data\n",
    "        df.drop(columns = iter_column_name, inplace=True)\n",
    "        print(f'Winsorized column {iter_column_name} to {new_column_name} and removed original column.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing missing numerical values w/ their mean\n",
    "Description TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter_column_name in df.select_dtypes(include=np.number).columns.tolist():\n",
    "    num_missing = np.sum(df[iter_column_name].isnull(), axis = 0)\n",
    "\n",
    "    if num_missing > 0:\n",
    "        new_column_name = iter_column_name + '_replacedMissing'\n",
    "        mean = get_stat(iter_column_name, 'mean')\n",
    "\n",
    "        df[new_column_name] = df[iter_column_name].fillna(value=mean,\n",
    "                                                          inplace=False)\n",
    "        df.drop(columns = iter_column_name, inplace=True)\n",
    "\n",
    "        # TODO: get a count of the number changed.\n",
    "        print(f'Replaced missing values in column {iter_column_name} with the mean and created new column {new_column_name}. Removed original column')\n",
    "    else:\n",
    "        print(f'No missing values detected in column {iter_column_name}, no changes made. Original column left intact.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing numerical ranges\n",
    "Description TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df_local, column_name, normalize_method_name):\n",
    "    \"\"\"docstring TBD\"\"\"\n",
    "    df_temp = df_local.copy()\n",
    "    new_columnname = column_name + '_normalized'\n",
    "\n",
    "    if normalize_method_name == 'absolute_range':\n",
    "        df_temp[new_columnname] = df_temp[column_name] / df_temp[column_name].abs().max()\n",
    "\n",
    "    elif normalize_method_name == 'min_max':\n",
    "        \"\"\"rescales a features to be in the range [0,1]\"\"\"\n",
    "        df_temp[new_columnname] = (df_temp[column_name] - df_temp[column_name].min()) / (df_temp[column_name].max() - df_temp[column_name].min())\n",
    "\n",
    "    elif normalize_method_name == 'z_score':\n",
    "        df_temp[new_columnname] = (df_temp[column_name] - df_temp[column_name].mean()) / df_temp[column_name].std()\n",
    "\n",
    "    else:\n",
    "        raise NameError('Unrecogized normalization method')\n",
    "\n",
    "    df_temp.drop(columns = column_name, inplace=True)\n",
    "    print(f'Normalized column {column_name} into {new_columnname} using {normalize_method_name}. Removed original.')\n",
    "    return df_temp\n",
    "\n",
    "\n",
    "# iterate through the list of current numeric columns\n",
    "for iter_column_name in df.select_dtypes(include=np.number).columns.tolist():\n",
    "    df = normalize(df, iter_column_name, NORMALIZE_METHOD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting actors and characters to one-hot encoded columns\n",
    "Locate string columns that have a small number of unique values and replace them with one-hot encoded versions, then remove the original column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a one-hot encoded version in a new dataframe\n",
    "temp_df = pd.get_dummies(df['episode_type'], prefix='episode_type_')\n",
    "\n",
    "# merge the new dataframe into the existing one\n",
    "df.join(temp_df)\n",
    "\n",
    "# remove the original column now that it has been encoded\n",
    "\n",
    "# into the existing dataframe\n",
    "df.drop(columns = 'episode_type', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_LIST_IN_CHAR = {\"himself\": \"\",\n",
    "                        \"herself\": \"\",\n",
    "                        \"themself\": \"\",\n",
    "                        \" and \": \";\",\n",
    "                        \",\": \";\",\n",
    "                        \"  \": \" \",\n",
    "                        \";;\": \";\"}\n",
    "\n",
    "def convert_cbb_guest_and_character_list3(single_episode_guest_list_str: str) -> list['str']:\n",
    "    \"\"\"Takes the ; delimited list of guests and characters for a single\n",
    "    episode. Converts them into two arrays: one for guests (actors) and one\n",
    "    for characters\"\"\"\n",
    "\n",
    "    # split out the episode guest list string into an array using the delimiter\n",
    "    single_episode_guest_list_array = single_episode_guest_list_str.split(';')\n",
    "\n",
    "    # define empty arrays\n",
    "    actors = \"\"\n",
    "    characters = \"none\"\n",
    "\n",
    "    # iterate through each guest/actor and what characters they play (if any)\n",
    "    for iter_str in single_episode_guest_list_array:\n",
    "        next_actor, next_character = convert_cbb_guest_instance_to_strings2(\n",
    "            iter_str)\n",
    "\n",
    "        # add the actor if there is one\n",
    "        if len(next_actor) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            if actors == \"\":\n",
    "                actors = str(next_actor)\n",
    "            else:\n",
    "                next_actor = str(next_actor)\n",
    "                actors = str(actors) + ';' + str(next_actor)\n",
    "\n",
    "        # add the character(s) if there are at least 1\n",
    "        if len(next_character) == 0:\n",
    "            continue\n",
    "        elif len(next_character) == 1:\n",
    "            characters = next_character[0]\n",
    "        else:\n",
    "\n",
    "            for ch in next_character:\n",
    "                if characters == \"none\":\n",
    "                    characters = str(ch)\n",
    "                else:\n",
    "                    characters = str(characters) + ';' + str(ch)\n",
    "\n",
    "    return str(actors), str(characters)\n",
    "\n",
    "\n",
    "def replace_all_as_str(text: str, dic: dict) -> str:\n",
    "    \"\"\"searches a string and replaces all instances of found key/values \"\"\"\n",
    "    for i, j in dic.items():\n",
    "        text = text.replace(i, j)\n",
    "    return str(text)\n",
    "\n",
    "\n",
    "def convert_cbb_guest_instance_to_strings2(single_guest_appearance_as_str: str):\n",
    "    \"\"\"Converts a string that has a single guest and one or more characters\n",
    "    a list of actors (Guests) and a list of characters they play\"\"\"\n",
    "\n",
    "    # make sure it's not empty string\n",
    "    assert len(single_guest_appearance_as_str) > 0\n",
    "\n",
    "    # make sure it doesn't have a reserved delimiter in it\n",
    "    assert not re.search(';', single_guest_appearance_as_str)\n",
    "\n",
    "    # if the guest plays at least one character, it will have ' as ' in it\n",
    "    if re.search(' as ', single_guest_appearance_as_str):\n",
    "        # extract guest name and list of characters\n",
    "        actor_name, character_list_as_str = single_guest_appearance_as_str.split(\n",
    "            ' as ', 1)\n",
    "        # strip out \"as himself\" or \"as herself\" and other non-characters\n",
    "        character_list_as_array = replace_all_as_str(\n",
    "            character_list_as_str, REPLACE_LIST_IN_CHAR).split(';')\n",
    "        if '' in character_list_as_array:\n",
    "            character_list_as_array.remove('')\n",
    "        # remove both leading and trailing whitespace from the character name\n",
    "        character_list_as_array = [i.strip() for i in character_list_as_array]\n",
    "        return str(actor_name), character_list_as_array\n",
    "\n",
    "    # else isn't necessary, got dinged by PyLint on it\n",
    "    # guest doesn't play a character, just themselves\n",
    "    # return an empty array for character list\n",
    "    # assert not re.search(',', single_guest_appearance_as_str)\n",
    "    # assert not re.search('/', single_guest_appearance_as_str)\n",
    "    return str(single_guest_appearance_as_str), \"\"\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# initialize some empty object columns\n",
    "df['actors'] = [[]] * len(df.index)\n",
    "df['characters'] = [[]] * len(df.index)\n",
    "df['num_actors'] = 0 * len(df.index) # set default to zero, important\n",
    "df['num_chars'] = 0 * len(df.index) # set default to zero, important\n",
    "\n",
    "actor_counter = Counter([])\n",
    "char_counter = Counter([])\n",
    "\n",
    "for ind in df.index:\n",
    "    orig = df['guests_and_characters_from_wikipedia_semicolon_delimited'][ind]\n",
    "\n",
    "    actors, characters = convert_cbb_guest_and_character_list3(orig)\n",
    "\n",
    "    actors_list = actors.split(';')\n",
    "    char_list = characters.split(';')\n",
    "    actor_counter.update(actors_list)\n",
    "    char_counter.update(char_list)\n",
    "\n",
    "    # assignment:\n",
    "    df.loc[df.index == ind, 'actors'] = actors\n",
    "    df.loc[df.index == ind, 'characters'] = characters\n",
    "\n",
    "    if actors != 'none':\n",
    "        df.loc[df.index == ind, 'num_actors'] = actors.count(';') + 1\n",
    "\n",
    "    if characters != 'none':\n",
    "        df.loc[df.index == ind, 'num_chars'] = characters.count(';') + 1\n",
    "\n",
    "# remove the original column\n",
    "df.drop(columns = 'guests_and_characters_from_wikipedia_semicolon_delimited',\n",
    "        inplace=True)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Analyzing the actor counts\n",
    "\n",
    "number_of_unique_actors = len(actor_counter.keys())\n",
    "number_of_total_actor_appearances = actor_counter.total()\n",
    "\n",
    "print(f'# of unique actors: {number_of_unique_actors}')\n",
    "print(f'# of actor appearances: {number_of_total_actor_appearances}')\n",
    "\n",
    "vals_array = np.array(actor_counter.most_common())[:, 1]\n",
    "csum = np.cumsum(vals_array, dtype=int) / number_of_total_actor_appearances\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(csum)\n",
    "ax.set(xlabel='Number of most frequent actors included', ylabel='Coverage (%)',\n",
    "        title='Searching for the number of actors to one-hot encode')\n",
    "\n",
    "for iter_interesting_value in INTERESTING_PERCENTILES:\n",
    "    \"\"\"docstring TBD\"\"\"\n",
    "    i = find_nearest_index(csum, iter_interesting_value)\n",
    "    p = iter_interesting_value * 100\n",
    "    print(f'{p:.1f}% coverage requires {i:3} actors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing the char counts\n",
    "\n",
    "number_of_unique_chars = len(char_counter.keys())\n",
    "number_of_total_char_appearances = char_counter.total()\n",
    "\n",
    "print(f'# of unique chars: {number_of_unique_chars}')\n",
    "print(f'# of char appearances: {number_of_total_char_appearances}')\n",
    "\n",
    "vals_array = np.array(char_counter.most_common())[:, 1]\n",
    "csum = np.cumsum(vals_array, dtype=int) / number_of_total_char_appearances\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(csum)\n",
    "ax.set(xlabel='Number of most frequent chars included', ylabel='Coverage (%)',\n",
    "        title='Searching for the number of chars to one-hot encode')\n",
    "\n",
    "for iter_interesting_value in INTERESTING_PERCENTILES:\n",
    "    i = find_nearest_index(csum, iter_interesting_value)\n",
    "    p = iter_interesting_value * 100\n",
    "    print(f'{p:.1f}% coverage requires {i:3} chars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-order the columns\n",
    "Sort the column names alphabetically, but make sure the 'label' column is always last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = sorted(df.columns)\n",
    "column_order.remove('label')\n",
    "column_order.append('label')\n",
    "df = df.reindex(column_order, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "# check for any remaining strings\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the final datatypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show some sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary stuff for testing\n",
    "rows_to_drop = df[df['data_set'] != 'training'].index\n",
    "df.drop(rows_to_drop, inplace=True)\n",
    "\n",
    "df.drop(columns = ['actors', 'characters', 'data_set'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the changed data into a new file\n",
    "Description TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_prefix = os.path.splitext(infile)[0]\n",
    "outfile = output_file_prefix + '_train.csv'\n",
    "\n",
    "df.to_csv(outfile, index=False)\n",
    "print(f'Training data saved to new CSV file:\\n{outfile}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
